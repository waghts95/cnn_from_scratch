{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“˜ Assignment Roadmap: CNN Architecture Implementation\n",
        "\n",
        "This roadmap follows the official assignment README step by step.  \n",
        "Each part lists the requirements and our implementation progress.  \n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Part 1: CNN Layer Implementation (40 points)\n",
        "- [x] **Conv2D Layer** â†’ forward + backward, stride & padding, He initialization  \n",
        "- [x] **MaxPool2D Layer** â†’ forward + backward, gradient routing  \n",
        "- [x] **Flatten Layer**  \n",
        "- [x] **Dense Layer (Fully Connected)**  \n",
        "- [x] **ReLU Activation**  \n",
        "- [x] **Dropout / Dropout2D**  \n",
        "- [x] **BatchNorm2D**  \n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Part 2: CNN Architectures (30 points)\n",
        "- [x] **LeNet-5** â†’ implemented with BatchNorm  \n",
        "- [x] **Mini-VGG** â†’ implemented with BatchNorm + Dropout  \n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Part 3: CIFAR-10 Classification (20 points)\n",
        "\n",
        "### 3.1 Data Preprocessing\n",
        "- [x] Data normalization ([0,1] scaling)  \n",
        "- [x] Data augmentation (flip, rotation, shift)  \n",
        "- [ ] Cropping augmentation (explicit in README, but skipped here)  \n",
        "- [x] Train/validation/test split  \n",
        "\n",
        "### 3.2 Training\n",
        "- [x] Training loop with forward â†’ loss â†’ backward â†’ update  \n",
        "- [x] SGD optimizer  \n",
        "- [x] Cross-entropy loss with softmax  \n",
        "- [x] Learning rate scheduling (step decay scheduler)  \n",
        "- [ ] Plot training/validation metrics (loss & accuracy curves)  \n",
        "\n",
        "### 3.3 Evaluation\n",
        "- [x] Accuracy calculation  \n",
        "- [x] Confusion matrix  \n",
        "- [x] Per-class accuracy  \n",
        "- [x] Confusion matrix visualization  \n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Part 4: Feature Visualization (10 points)\n",
        "- [x] Filter visualization (first Conv layer filters)  \n",
        "- [x] Feature map visualization (activations at chosen layers)  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "p96eC2igaPuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required Imports"
      ],
      "metadata": {
        "id": "CKTqbu49eOEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Required Imports\n",
        "# ==============================\n",
        "import numpy as np   # NumPy is used for array operations\n",
        "from typing import Tuple  # for type hints\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from scipy.ndimage import rotate\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "bWZXBvmQdgH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: CNN Layer Implementation"
      ],
      "metadata": {
        "id": "0H0IWiZ2a0KA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hB5jpkB94NOt"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ==============================\n",
        "# Base Layer Class\n",
        "# ==============================\n",
        "class Layer:\n",
        "    \"\"\"\n",
        "    Base class for all neural network layers.\n",
        "    Every layer must have forward() and backward() methods.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.trainable = True        # if the layer has weights (Conv, Dense)\n",
        "        self.params = {}             # store weights\n",
        "        self.grads = {}              # store gradients\n",
        "        self.cache = {}              # store intermediate values for backprop\n",
        "\n",
        "    def forward(self, x: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Conv2D Layer\n",
        "# ==============================\n",
        "class Conv2D(Layer):\n",
        "    \"\"\"\n",
        "    2D Convolution Layer\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    in_channels : int   â†’ Number of input channels (e.g., 3 for RGB images)\n",
        "    out_channels : int  â†’ Number of filters (output channels)\n",
        "    kernel_size : int   â†’ Size of the convolution filter (e.g., 3 for 3x3)\n",
        "    stride : int        â†’ How much the filter moves each step\n",
        "    padding : str       â†’ 'same' (keep size same) or 'valid' (no padding)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int,\n",
        "                 kernel_size: int = 3, stride: int = 1,\n",
        "                 padding: str = 'same'):\n",
        "        super().__init__()\n",
        "\n",
        "        # Save layer configuration\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = (kernel_size, kernel_size)  # assume square filters\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        # He initialization: good for ReLU networks\n",
        "        kh, kw = self.kernel_size\n",
        "        scale = np.sqrt(2.0 / (in_channels * kh * kw))\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        # W shape: (out_channels, in_channels, kernel_h, kernel_w)\n",
        "        self.params['W'] = np.random.randn(out_channels, in_channels, kh, kw) * scale\n",
        "        # Bias for each filter\n",
        "        self.params['b'] = np.zeros((out_channels, 1))\n",
        "\n",
        "        # Cache for storing intermediate values for backward\n",
        "        self.cache = {}\n",
        "\n",
        "    def _get_pad_width(self, input_shape: Tuple[int, ...]) -> Tuple[int, int]:\n",
        "        \"\"\"\n",
        "        Calculate padding for 'same' or 'valid'.\n",
        "        \"\"\"\n",
        "        _, _, H, W = input_shape\n",
        "        kh, kw = self.kernel_size\n",
        "\n",
        "        if self.padding == 'same':\n",
        "            # Formula ensures output size â‰ˆ input size\n",
        "            pad_h = max((np.ceil(H / self.stride) - 1) * self.stride + kh - H, 0)\n",
        "            pad_w = max((np.ceil(W / self.stride) - 1) * self.stride + kw - W, 0)\n",
        "            return int(pad_h // 2), int(pad_w // 2)\n",
        "        elif self.padding == 'valid':\n",
        "            return 0, 0\n",
        "        else:\n",
        "            raise ValueError(\"Padding must be 'same' or 'valid'\")\n",
        "\n",
        "    def _pad_input(self, x: np.ndarray, pad_h: int, pad_w: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Pad input with zeros around the border.\n",
        "        x shape: (batch, channels, height, width)\n",
        "        \"\"\"\n",
        "        return np.pad(x, ((0, 0), (0, 0), (pad_h, pad_h), (pad_w, pad_w)), mode='constant')\n",
        "\n",
        "    def forward(self, x: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Forward pass of convolution.\n",
        "        Input shape:  (batch, in_channels, H, W)\n",
        "        Output shape: (batch, out_channels, H_out, W_out)\n",
        "        \"\"\"\n",
        "        batch_size, _, H, W = x.shape\n",
        "        kh, kw = self.kernel_size\n",
        "        stride = self.stride\n",
        "        pad_h, pad_w = self._get_pad_width(x.shape)\n",
        "\n",
        "        # Pad input if necessary\n",
        "        x_padded = self._pad_input(x, pad_h, pad_w)\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        H_out = (H + 2*pad_h - kh) // stride + 1\n",
        "        W_out = (W + 2*pad_w - kw) // stride + 1\n",
        "\n",
        "        # Allocate output tensor\n",
        "        out = np.zeros((batch_size, self.out_channels, H_out, W_out))\n",
        "\n",
        "        # Convolution operation\n",
        "        W = self.params['W']\n",
        "        b = self.params['b']\n",
        "\n",
        "        for n in range(batch_size):          # for each image\n",
        "            for f in range(self.out_channels):  # for each filter\n",
        "                for i in range(H_out):      # slide vertically\n",
        "                    for j in range(W_out):  # slide horizontally\n",
        "                        h_start = i * stride\n",
        "                        h_end = h_start + kh\n",
        "                        w_start = j * stride\n",
        "                        w_end = w_start + kw\n",
        "\n",
        "                        # Extract the patch of the image\n",
        "                        patch = x_padded[n, :, h_start:h_end, w_start:w_end]\n",
        "\n",
        "                        # Convolution = sum(patch * filter) + bias\n",
        "                        out[n, f, i, j] = np.sum(patch * W[f]) + b[f]\n",
        "\n",
        "        # Save values for backward pass\n",
        "        self.cache = {\"x\": x, \"x_padded\": x_padded, \"pad_h\": pad_h, \"pad_w\": pad_w}\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Backward pass of convolution.\n",
        "        grad_output: gradient of loss w.r.t. layer output\n",
        "        Returns: gradient w.r.t. layer input\n",
        "        \"\"\"\n",
        "        x = self.cache['x']\n",
        "        x_padded = self.cache['x_padded']\n",
        "        pad_h, pad_w = self.cache['pad_h'], self.cache['pad_w']\n",
        "\n",
        "        batch_size, _, H, W = x.shape\n",
        "        kh, kw = self.kernel_size\n",
        "        stride = self.stride\n",
        "        _, _, H_out, W_out = grad_output.shape\n",
        "\n",
        "        # Initialize gradients\n",
        "        dW = np.zeros_like(self.params['W'])\n",
        "        db = np.zeros_like(self.params['b'])\n",
        "        dx_padded = np.zeros_like(x_padded)\n",
        "\n",
        "        # Compute gradients\n",
        "        for n in range(batch_size):\n",
        "            for f in range(self.out_channels):\n",
        "                for i in range(H_out):\n",
        "                    for j in range(W_out):\n",
        "                        h_start = i * stride\n",
        "                        h_end = h_start + kh\n",
        "                        w_start = j * stride\n",
        "                        w_end = w_start + kw\n",
        "\n",
        "                        patch = x_padded[n, :, h_start:h_end, w_start:w_end]\n",
        "\n",
        "                        # Gradients of weights and bias\n",
        "                        dW[f] += grad_output[n, f, i, j] * patch\n",
        "                        db[f] += grad_output[n, f, i, j]\n",
        "\n",
        "                        # Gradient wrt input\n",
        "                        dx_padded[n, :, h_start:h_end, w_start:w_end] += grad_output[n, f, i, j] * self.params['W'][f]\n",
        "\n",
        "        # Remove padding from dx\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            dx = dx_padded[:, :, pad_h:-pad_h, pad_w:-pad_w]\n",
        "        else:\n",
        "            dx = dx_padded\n",
        "\n",
        "        # Save gradients\n",
        "        self.grads['W'] = dW\n",
        "        self.grads['b'] = db\n",
        "\n",
        "        return dx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2D(Layer):\n",
        "    \"\"\"\n",
        "    2D Max Pooling Layer\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    pool_size : int or tuple\n",
        "        Size of pooling window (e.g., 2 â†’ 2x2 pooling)\n",
        "    stride : int\n",
        "        Step size for moving the pooling window\n",
        "        If None, defaults to pool_size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pool_size: int = 2, stride: int = None):\n",
        "        super().__init__()\n",
        "\n",
        "        # If given a single int, make it a square window\n",
        "        self.pool_size = (pool_size, pool_size) if isinstance(pool_size, int) else pool_size\n",
        "        self.stride = stride if stride is not None else pool_size\n",
        "\n",
        "        # Pooling has no trainable parameters\n",
        "        self.trainable = False\n",
        "        self.cache = {}\n",
        "\n",
        "    def forward(self, x: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Forward pass of max pooling.\n",
        "\n",
        "        Input shape:  (batch, channels, H, W)\n",
        "        Output shape: (batch, channels, H_out, W_out)\n",
        "        \"\"\"\n",
        "        batch_size, channels, H, W = x.shape\n",
        "        ph, pw = self.pool_size\n",
        "        stride = self.stride\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        H_out = (H - ph) // stride + 1\n",
        "        W_out = (W - pw) // stride + 1\n",
        "\n",
        "        # Allocate output and mask (to remember max locations)\n",
        "        out = np.zeros((batch_size, channels, H_out, W_out))\n",
        "        max_indices = {}\n",
        "\n",
        "        for n in range(batch_size):\n",
        "            for c in range(channels):\n",
        "                for i in range(H_out):\n",
        "                    for j in range(W_out):\n",
        "                        h_start = i * stride\n",
        "                        h_end = h_start + ph\n",
        "                        w_start = j * stride\n",
        "                        w_end = w_start + pw\n",
        "\n",
        "                        # Extract pooling region\n",
        "                        region = x[n, c, h_start:h_end, w_start:w_end]\n",
        "\n",
        "                        # Find maximum value in region\n",
        "                        max_val = np.max(region)\n",
        "                        out[n, c, i, j] = max_val\n",
        "\n",
        "                        # Store index of max for backward\n",
        "                        max_pos = np.unravel_index(np.argmax(region), region.shape)\n",
        "                        max_indices[(n, c, i, j)] = (h_start + max_pos[0], w_start + max_pos[1])\n",
        "\n",
        "        # Save cache for backward pass\n",
        "        self.cache = {\"x_shape\": x.shape, \"max_indices\": max_indices,\n",
        "                      \"pool_size\": self.pool_size, \"stride\": stride}\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Backward pass of max pooling.\n",
        "\n",
        "        grad_output: gradient of loss w.r.t. pooled output\n",
        "        Returns: gradient w.r.t. input (same shape as forward input)\n",
        "        \"\"\"\n",
        "        x_shape = self.cache[\"x_shape\"]\n",
        "        max_indices = self.cache[\"max_indices\"]\n",
        "\n",
        "        # Initialize gradient w.r.t input with zeros\n",
        "        dx = np.zeros(x_shape)\n",
        "\n",
        "        for (n, c, i, j), (h_idx, w_idx) in max_indices.items():\n",
        "            # Route gradient only to the max location\n",
        "            dx[n, c, h_idx, w_idx] += grad_output[n, c, i, j]\n",
        "\n",
        "        return dx\n"
      ],
      "metadata": {
        "id": "MKYO5Ju49H2o"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Flatten Layer\n",
        "# ==============================\n",
        "class Flatten(Layer):\n",
        "    \"\"\"\n",
        "    Flatten layer converts 4D input (batch, channels, H, W)\n",
        "    into 2D (batch, features).\n",
        "    Example:\n",
        "        Input shape:  (32, 16, 7, 7)\n",
        "        Output shape: (32, 16*7*7)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.trainable = False  # no weights\n",
        "\n",
        "    def forward(self, x: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "        # Save input shape for backward\n",
        "        self.cache[\"input_shape\"] = x.shape\n",
        "        return x.reshape(x.shape[0], -1)\n",
        "\n",
        "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
        "        # Reshape gradient back to original input shape\n",
        "        return grad_output.reshape(self.cache[\"input_shape\"])\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Dense (Fully Connected) Layer\n",
        "# ==============================\n",
        "class Dense(Layer):\n",
        "    \"\"\"\n",
        "    Fully connected (linear) layer.\n",
        "    y = xW^T + b\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    in_features : int  â†’ number of input neurons\n",
        "    out_features : int â†’ number of output neurons\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        # He initialization for weights\n",
        "        scale = np.sqrt(2.0 / in_features)\n",
        "        self.params[\"W\"] = np.random.randn(out_features, in_features) * scale\n",
        "        self.params[\"b\"] = np.zeros((out_features, 1))\n",
        "\n",
        "    def forward(self, x: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "        Input:  (batch, in_features)\n",
        "        Output: (batch, out_features)\n",
        "        \"\"\"\n",
        "        self.cache[\"x\"] = x\n",
        "        return x.dot(self.params[\"W\"].T) + self.params[\"b\"].T\n",
        "\n",
        "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Backward pass.\n",
        "        grad_output: (batch, out_features)\n",
        "        Returns: gradient wrt input (batch, in_features)\n",
        "        \"\"\"\n",
        "        x = self.cache[\"x\"]\n",
        "\n",
        "        # Gradients wrt weights and biases\n",
        "        self.grads[\"W\"] = grad_output.T.dot(x)      # (out_features, in_features)\n",
        "        self.grads[\"b\"] = np.sum(grad_output, axis=0, keepdims=True).T  # (out_features, 1)\n",
        "\n",
        "        # Gradient wrt input\n",
        "        grad_input = grad_output.dot(self.params[\"W\"])  # (batch, in_features)\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ReLU Activation\n",
        "# ==============================\n",
        "class ReLU(Layer):\n",
        "    \"\"\"\n",
        "    ReLU Activation: f(x) = max(0, x)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.trainable = False  # no parameters\n",
        "\n",
        "    def forward(self, x: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "        # Store mask of where x > 0 for backward\n",
        "        self.cache[\"mask\"] = (x > 0).astype(float)\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
        "        # Pass gradient only where input was positive\n",
        "        return grad_output * self.cache[\"mask\"]\n",
        "\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Dropout2D Implementation\n",
        "# ==============================\n",
        "\n",
        "class Dropout(Layer):\n",
        "    \"\"\"\n",
        "    Standard Dropout (for Dense layers).\n",
        "    Randomly drops individual neurons.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.trainable = False\n",
        "\n",
        "    def forward(self, x: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "        if training:\n",
        "            mask = (np.random.rand(*x.shape) > self.p).astype(float)\n",
        "            self.cache[\"mask\"] = mask\n",
        "            return x * mask / (1.0 - self.p)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
        "        mask = self.cache.get(\"mask\", 1.0)\n",
        "        return grad_output * mask / (1.0 - self.p)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Batch Normalization\n",
        "# ==============================\n",
        "\n",
        "class BatchNorm2D(Layer):\n",
        "    \"\"\"\n",
        "    Batch Normalization for CNNs (per-channel).\n",
        "    Normalizes across batch and spatial dimensions, then scales & shifts.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_features: int, eps: float = 1e-5, momentum: float = 0.9):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        # Learnable parameters\n",
        "        self.params[\"gamma\"] = np.ones((num_features, 1))  # scale\n",
        "        self.params[\"beta\"] = np.zeros((num_features, 1))  # shift\n",
        "\n",
        "        # Running stats (for inference)\n",
        "        self.running_mean = np.zeros((num_features, 1))\n",
        "        self.running_var = np.ones((num_features, 1))\n",
        "\n",
        "    def forward(self, x: np.ndarray, training: bool = True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "        Input: (N, C, H, W)\n",
        "        \"\"\"\n",
        "        N, C, H, W = x.shape\n",
        "\n",
        "        if training:\n",
        "            # Compute mean/var over batch+spatial dims\n",
        "            mean = np.mean(x, axis=(0, 2, 3), keepdims=True)\n",
        "            var = np.var(x, axis=(0, 2, 3), keepdims=True)\n",
        "\n",
        "            # Normalize\n",
        "            x_hat = (x - mean) / np.sqrt(var + self.eps)\n",
        "\n",
        "            # Update running stats\n",
        "            self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * mean.reshape(C, 1)\n",
        "            self.running_var = self.momentum * self.running_var + (1 - self.momentum) * var.reshape(C, 1)\n",
        "\n",
        "            # Cache for backward\n",
        "            self.cache = {\"x\": x, \"x_hat\": x_hat, \"mean\": mean, \"var\": var}\n",
        "        else:\n",
        "            # Use running stats for inference\n",
        "            mean = self.running_mean.reshape(1, C, 1, 1)\n",
        "            var = self.running_var.reshape(1, C, 1, 1)\n",
        "            x_hat = (x - mean) / np.sqrt(var + self.eps)\n",
        "\n",
        "        # Scale + shift\n",
        "        out = self.params[\"gamma\"].reshape(1, C, 1, 1) * x_hat + self.params[\"beta\"].reshape(1, C, 1, 1)\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Backward pass.\n",
        "        \"\"\"\n",
        "        x = self.cache[\"x\"]\n",
        "        x_hat = self.cache[\"x_hat\"]\n",
        "        mean = self.cache[\"mean\"]\n",
        "        var = self.cache[\"var\"]\n",
        "        N, C, H, W = x.shape\n",
        "        m = N * H * W  # number of elements per channel\n",
        "\n",
        "        # Grad wrt gamma and beta\n",
        "        self.grads[\"gamma\"] = np.sum(grad_output * x_hat, axis=(0, 2, 3), keepdims=True).reshape(C, 1)\n",
        "        self.grads[\"beta\"] = np.sum(grad_output, axis=(0, 2, 3), keepdims=True).reshape(C, 1)\n",
        "\n",
        "        # Grad wrt input\n",
        "        dx_hat = grad_output * self.params[\"gamma\"].reshape(1, C, 1, 1)\n",
        "        dvar = np.sum(dx_hat * (x - mean) * -0.5 * (var + self.eps) ** (-1.5), axis=(0, 2, 3), keepdims=True)\n",
        "        dmean = np.sum(dx_hat * -1 / np.sqrt(var + self.eps), axis=(0, 2, 3), keepdims=True) + \\\n",
        "                dvar * np.sum(-2 * (x - mean), axis=(0, 2, 3), keepdims=True) / m\n",
        "\n",
        "        dx = dx_hat / np.sqrt(var + self.eps) + dvar * 2 * (x - mean) / m + dmean / m\n",
        "        return dx\n"
      ],
      "metadata": {
        "id": "qOI-N-bW9330"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: CNN Architectures"
      ],
      "metadata": {
        "id": "l9O7ikdGbE5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now letâ€™s assemble the LeNet-5 architecture using the building blocks we already coded (Conv2D, ReLU, MaxPool2D, Flatten, Dense)"
      ],
      "metadata": {
        "id": "LnKLAy8A_HdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet-5 Architecture Reminder (from your README)"
      ],
      "metadata": {
        "id": "wuSypWB2_VF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Input (32x32x3) â†’\n",
        "Conv(6, 5x5) â†’ ReLU â†’ MaxPool(2x2) â†’\n",
        "Conv(16, 5x5) â†’ ReLU â†’ MaxPool(2x2) â†’\n",
        "Flatten â†’ FC(120) â†’ ReLU â†’ FC(84) â†’ ReLU â†’ FC(10)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ZKJLCyaR_LRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation"
      ],
      "metadata": {
        "id": "TU7N1p5j_uSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5:\n",
        "    \"\"\"\n",
        "    LeNet-5 with BatchNorm added\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes: int = 10):\n",
        "        self.layers = [\n",
        "            Conv2D(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=\"valid\"),\n",
        "            BatchNorm2D(num_features=6),\n",
        "            ReLU(),\n",
        "            MaxPool2D(pool_size=2, stride=2),\n",
        "\n",
        "            Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=\"valid\"),\n",
        "            BatchNorm2D(num_features=16),\n",
        "            ReLU(),\n",
        "            MaxPool2D(pool_size=2, stride=2),\n",
        "\n",
        "            Flatten(),\n",
        "\n",
        "            Dense(in_features=16*5*5, out_features=120),\n",
        "            ReLU(),\n",
        "\n",
        "            Dense(in_features=120, out_features=84),\n",
        "            ReLU(),\n",
        "\n",
        "            Dense(in_features=84, out_features=num_classes)\n",
        "        ]\n",
        "\n",
        "    def forward(self, x, training=True):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x, training)\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        for layer in reversed(self.layers):\n",
        "            grad_output = layer.backward(grad_output)\n",
        "        return grad_output\n",
        "\n",
        "    def get_params(self):\n",
        "        params = {}\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            if layer.trainable:\n",
        "                for k, v in layer.params.items():\n",
        "                    params[f\"layer{idx}_{k}\"] = v\n",
        "        return params\n",
        "\n",
        "    def get_grads(self):\n",
        "        grads = {}\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            if layer.trainable:\n",
        "                for k, v in layer.grads.items():\n",
        "                    grads[f\"layer{idx}_{k}\"] = v\n",
        "        return grads\n"
      ],
      "metadata": {
        "id": "AOxNOWDy97QD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "model = LeNet5(num_classes=10)\n",
        "X = np.random.randn(2, 3, 32, 32)  # dummy batch of 2 RGB images\n",
        "out = model.forward(X)\n",
        "print(\"Output shape:\", out.shape)  # (2, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxhddA23_8Ir",
        "outputId": "b68bd16b-e8ec-4a77-d0f9-cc757a78702e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1210623038.py:132: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  out[n, f, i, j] = np.sum(patch * W[f]) + b[f]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (2, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have Conv2D, MaxPool2D, Flatten, Dense, ReLU working, letâ€™s build the **Mini-VGG architecture** described in your README."
      ],
      "metadata": {
        "id": "PqMKRh46BL9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Input (32x32x3) â†’\n",
        "Conv(32, 3x3) â†’ ReLU â†’ Conv(32, 3x3) â†’ ReLU â†’ MaxPool(2x2) â†’\n",
        "Conv(64, 3x3) â†’ ReLU â†’ Conv(64, 3x3) â†’ ReLU â†’ MaxPool(2x2) â†’\n",
        "Conv(128, 3x3) â†’ ReLU â†’ Conv(128, 3x3) â†’ ReLU â†’ MaxPool(2x2) â†’\n",
        "Flatten â†’ FC(256) â†’ ReLU â†’ Dropout(0.5) â†’ FC(10)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "LDooVmlOBPqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Simplified VGG-style network for CIFAR-10 (input: 32x32x3, output: 10 classes)\n",
        "\n",
        "class MiniVGG:\n",
        "\n",
        "    def __init__(self, num_classes: int = 10):\n",
        "        self.layers = [\n",
        "            # Block 1\n",
        "            Conv2D(3, 32, kernel_size=3, stride=1, padding=\"same\"),\n",
        "            BatchNorm2D(32),\n",
        "            ReLU(),\n",
        "            Conv2D(32, 32, kernel_size=3, stride=1, padding=\"same\"),\n",
        "            BatchNorm2D(32),\n",
        "            ReLU(),\n",
        "            MaxPool2D(pool_size=2, stride=2),\n",
        "\n",
        "            # Block 2\n",
        "            Conv2D(32, 64, kernel_size=3, stride=1, padding=\"same\"),\n",
        "            BatchNorm2D(64),\n",
        "            ReLU(),\n",
        "            Conv2D(64, 64, kernel_size=3, stride=1, padding=\"same\"),\n",
        "            BatchNorm2D(64),\n",
        "            ReLU(),\n",
        "            MaxPool2D(pool_size=2, stride=2),\n",
        "\n",
        "            # Block 3\n",
        "            Conv2D(64, 128, kernel_size=3, stride=1, padding=\"same\"),\n",
        "            BatchNorm2D(128),\n",
        "            ReLU(),\n",
        "            Conv2D(128, 128, kernel_size=3, stride=1, padding=\"same\"),\n",
        "            BatchNorm2D(128),\n",
        "            ReLU(),\n",
        "            MaxPool2D(pool_size=2, stride=2),\n",
        "\n",
        "            # Fully connected\n",
        "            Flatten(),\n",
        "            Dense(128*4*4, 256),\n",
        "            ReLU(),\n",
        "            Dropout(p=0.5),\n",
        "            Dense(256, num_classes)\n",
        "        ]\n",
        "\n",
        "    def forward(self, x, training=True):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x, training)\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        for layer in reversed(self.layers):\n",
        "            grad_output = layer.backward(grad_output)\n",
        "        return grad_output\n",
        "\n",
        "    def get_params(self):\n",
        "        params = {}\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            if layer.trainable:\n",
        "                for k, v in layer.params.items():\n",
        "                    params[f\"layer{idx}_{k}\"] = v\n",
        "        return params\n",
        "\n",
        "    def get_grads(self):\n",
        "        grads = {}\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            if layer.trainable:\n",
        "                for k, v in layer.grads.items():\n",
        "                    grads[f\"layer{idx}_{k}\"] = v\n",
        "        return grads\n"
      ],
      "metadata": {
        "id": "vkm7cLxKQ0Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes\n",
        "\n",
        "Padding = \"same\" ensures spatial dimensions stay the same after convolution.\n",
        "\n",
        "After 3 max poolings (stride=2):\n",
        "\n",
        "  1. Input 32Ã—32 â†’ 16Ã—16 â†’ 8Ã—8 â†’ 4Ã—4\n",
        "\n",
        "  2. With 128 channels â†’ 128 Ã— 4 Ã— 4 = 2048 features.\n",
        "\n",
        "Dropout2D(p=0.5) randomly drops half of the feature maps during training to reduce overfitting."
      ],
      "metadata": {
        "id": "4GOZwN11B8n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Quick Test"
      ],
      "metadata": {
        "id": "RPPvjPSPCQKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Mini-VGG model\n",
        "model = MiniVGG(num_classes=10)\n",
        "# Dummy input: batch of 2 RGB images (32x32)\n",
        "X = np.random.randn(2, 3, 32, 32)\n",
        "# Forward pass\n",
        "out = model.forward(X, training=True)\n",
        "print(\"Output shape:\", out.shape)  # should be (2, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tv9ZWzKBXUr",
        "outputId": "215aa0eb-5ecb-4302-a0bc-d8979b254866"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1210623038.py:132: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  out[n, f, i, j] = np.sum(patch * W[f]) + b[f]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (2, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: CIFAR-10 Classification"
      ],
      "metadata": {
        "id": "kFH37N0_bovJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that LeNet-5 and Mini-VGG are built, the next step is to train them. For that, we need three key pieces:\n",
        "\n",
        "  1. Loss function â†’ Cross-Entropy (commonly used for classification).\n",
        "\n",
        "  2. Optimizer â†’ Stochastic Gradient Descent (SGD).\n",
        "\n",
        "  3. Training Loop â†’ to iterate over batches, forward â†’ loss â†’ backward â†’ update."
      ],
      "metadata": {
        "id": "h5FG7aXwDxLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Cross-Entropy Loss (with Softmax)"
      ],
      "metadata": {
        "id": "56cYzqH0D-yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossEntropyLoss:\n",
        "    \"\"\"\n",
        "    Cross-Entropy Loss with Softmax.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cache = {}\n",
        "\n",
        "    def forward(self, logits: np.ndarray, labels: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        logits: raw output from model (batch, num_classes)\n",
        "        labels: true class indices (batch,)\n",
        "        \"\"\"\n",
        "        # Shift logits for numerical stability\n",
        "        shifted_logits = logits - np.max(logits, axis=1, keepdims=True)\n",
        "\n",
        "        # Compute softmax probabilities\n",
        "        exp_logits = np.exp(shifted_logits)\n",
        "        probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "\n",
        "        # Negative log likelihood loss\n",
        "        N = logits.shape[0]\n",
        "        correct_logprobs = -np.log(probs[np.arange(N), labels])\n",
        "        loss = np.mean(correct_logprobs)\n",
        "\n",
        "        # Save probs + labels for backward\n",
        "        self.cache[\"probs\"] = probs\n",
        "        self.cache[\"labels\"] = labels\n",
        "        return loss\n",
        "\n",
        "    def backward(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Gradient of loss wrt logits.\n",
        "        \"\"\"\n",
        "        probs = self.cache[\"probs\"]\n",
        "        labels = self.cache[\"labels\"]\n",
        "        N = probs.shape[0]\n",
        "\n",
        "        grad_logits = probs.copy()\n",
        "        grad_logits[np.arange(N), labels] -= 1\n",
        "        grad_logits /= N\n",
        "        return grad_logits\n"
      ],
      "metadata": {
        "id": "LnhcV2FGD_Vq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Optimizer (SGD)"
      ],
      "metadata": {
        "id": "hqs-3uKsEO5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    Stochastic Gradient Descent optimizer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, lr=0.01):\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        Update model parameters using stored gradients.\n",
        "        \"\"\"\n",
        "        params = self.model.get_params()\n",
        "        grads = self.model.get_grads()\n",
        "\n",
        "        for key in params.keys():\n",
        "            params[key] -= self.lr * grads[key]\n"
      ],
      "metadata": {
        "id": "cxbpncgIERKS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Training Loop"
      ],
      "metadata": {
        "id": "VmhSBR2AET-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "    \"\"\"Compute accuracy\"\"\"\n",
        "    return np.mean(np.argmax(preds, axis=1) == labels)\n",
        "\n",
        "\n",
        "def train(model, X_train, y_train, X_val, y_val, epochs=5, batch_size=64, lr=0.01):\n",
        "    \"\"\"\n",
        "    Simple training loop for CNNs.\n",
        "    \"\"\"\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "    optimizer = SGD(model, lr=lr)\n",
        "\n",
        "    num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss, epoch_acc = 0, 0\n",
        "\n",
        "        # Shuffle training data\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            batch_idx = indices[i*batch_size:(i+1)*batch_size]\n",
        "            X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model.forward(X_batch, training=True)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn.forward(logits, y_batch)\n",
        "\n",
        "            # Backward pass\n",
        "            grad_logits = loss_fn.backward()\n",
        "            model.backward(grad_logits)\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track batch accuracy\n",
        "            acc = accuracy(logits, y_batch)\n",
        "            epoch_loss += loss\n",
        "            epoch_acc += acc\n",
        "\n",
        "        # Average over batches\n",
        "        epoch_loss /= num_batches\n",
        "        epoch_acc /= num_batches\n",
        "\n",
        "        # Validation\n",
        "        val_logits = model.forward(X_val, training=False)\n",
        "        val_loss = loss_fn.forward(val_logits, y_val)\n",
        "        val_acc = accuracy(val_logits, y_val)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "gz3JosRMEWQ6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example Usage**"
      ],
      "metadata": {
        "id": "SMnTIg46Efn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy CIFAR-like data (small for demo)\n",
        "X_train = np.random.randn(100, 3, 32, 32)\n",
        "y_train = np.random.randint(0, 10, 100)\n",
        "\n",
        "X_val = np.random.randn(20, 3, 32, 32)\n",
        "y_val = np.random.randint(0, 10, 20)\n",
        "\n",
        "# Pick a model (LeNet5 or MiniVGG)\n",
        "model = LeNet5(num_classes=10)\n",
        "# model = MiniVGG(num_classes=10)\n",
        "\n",
        "# Train\n",
        "train(model, X_train, y_train, X_val, y_val, epochs=3, batch_size=16, lr=0.01)\n"
      ],
      "metadata": {
        "id": "3clgPKB1Ecoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes\n",
        "\n",
        "  CrossEntropyLoss: combines softmax + negative log likelihood in one.\n",
        "\n",
        "  SGD: updates parameters after each batch.\n",
        "\n",
        "  Training loop:\n",
        "\n",
        "    Forward pass â†’ predictions\n",
        "\n",
        "    Compute loss\n",
        "\n",
        "    Backward pass â†’ gradients\n",
        "\n",
        "    Optimizer step â†’ update weights\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_IOT5r_OElET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s plug in real CIFAR-10 data instead of dummy arrays, so you can actually train LeNet-5 or Mini-VGG.\n",
        "\n",
        "Since weâ€™re coding this from scratch with NumPy only, weâ€™ll use Keras dataset loader (very convenient, no PyTorch/TensorFlow training needed)."
      ],
      "metadata": {
        "id": "IGtmz09uG4yy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: CIFAR-10 Loader"
      ],
      "metadata": {
        "id": "5m9rzbBjG8mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10(normalize=True):\n",
        "    \"\"\"\n",
        "    Load CIFAR-10 dataset and return NumPy arrays.\n",
        "    Shape:\n",
        "      X_train: (50000, 3, 32, 32)\n",
        "      y_train: (50000,)\n",
        "      X_test:  (10000, 3, 32, 32)\n",
        "      y_test:  (10000,)\n",
        "    \"\"\"\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "    # Convert from (N, 32, 32, 3) â†’ (N, 3, 32, 32)\n",
        "    X_train = X_train.transpose(0, 3, 1, 2).astype(np.float32)\n",
        "    X_test = X_test.transpose(0, 3, 1, 2).astype(np.float32)\n",
        "\n",
        "    # Flatten labels\n",
        "    y_train = y_train.flatten()\n",
        "    y_test = y_test.flatten()\n",
        "\n",
        "    # Normalize to [0,1] if required\n",
        "    if normalize:\n",
        "        X_train /= 255.0\n",
        "        X_test /= 255.0\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n"
      ],
      "metadata": {
        "id": "uuxZ_9qKEkLT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Train on CIFAR-10"
      ],
      "metadata": {
        "id": "yt0hewB5HD5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_train, y_train, X_test, y_test = load_cifar10()\n",
        "\n",
        "# Split validation set\n",
        "X_val, y_val = X_train[:5000], y_train[:5000]\n",
        "X_train, y_train = X_train[5000:], y_train[5000:]\n",
        "\n",
        "print(\"Train set:\", X_train.shape, y_train.shape)\n",
        "print(\"Val set:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# Choose a model\n",
        "model = LeNet5(num_classes=10)\n",
        "# model = MiniVGG(num_classes=10)   # <- More powerful, but slower\n",
        "\n",
        "# Train\n",
        "train(model, X_train, y_train, X_val, y_val,\n",
        "      epochs=5, batch_size=64, lr=0.01)\n",
        "\n",
        "# Final evaluation on test set\n",
        "loss_fn = CrossEntropyLoss()\n",
        "logits = model.forward(X_test, training=False)\n",
        "test_loss = loss_fn.forward(logits, y_test)\n",
        "test_acc = accuracy(logits, y_test)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zsi2gVHFTD",
        "outputId": "9595cd27-b062-40ba-adc1-36bf1be8a453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 0us/step\n",
            "Train set: (45000, 3, 32, 32) (45000,)\n",
            "Val set: (5000, 3, 32, 32) (5000,)\n",
            "Test set: (10000, 3, 32, 32) (10000,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1210623038.py:132: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  out[n, f, i, j] = np.sum(patch * W[f]) + b[f]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes**\n",
        "\n",
        "    Normalization â†’ Dividing by 255 scales pixels from [0,255] â†’ [0,1], which makes training stable.\n",
        "\n",
        "    Transpose â†’ Keras loads images as (N, H, W, C), but our network expects (N, C, H, W).\n",
        "\n",
        "    Split validation â†’ We take first 5000 images from training set as validation.\n",
        "\n",
        "    Training â†’ Youâ€™ll see epoch-wise loss and accuracy for both training and validation.\n",
        "\n",
        "    Test set â†’ Evaluate model after training."
      ],
      "metadata": {
        "id": "wHc92WgdHWSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âš ï¸ Note: Since our implementation is pure NumPy (no GPU acceleration), training on full CIFAR-10 will be slow.</br>\n",
        "ðŸ‘‰ For testing, you might want to use smaller subsets first, e.g., X_train[:2000], y_train[:2000]."
      ],
      "metadata": {
        "id": "82jufQHIHvQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s add data augmentation (as required in your assignment). This helps prevent overfitting and improves accuracy, especially for Mini-VGG.\n",
        "\n",
        "Weâ€™ll implement:\n",
        "\n",
        "    Random horizontal flip\n",
        "\n",
        "    Random shift (translation)\n",
        "\n",
        "    Random rotation"
      ],
      "metadata": {
        "id": "2L4QeK1vLfWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DataAugmentation:\n",
        "    \"\"\"\n",
        "    Data augmentation for CIFAR-10 images.\n",
        "    Works on NumPy arrays shaped (batch, C, H, W).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, horizontal_flip=True, rotation_range=15, shift_range=0.1):\n",
        "        self.horizontal_flip = horizontal_flip\n",
        "        self.rotation_range = rotation_range  # degrees\n",
        "        self.shift_range = shift_range        # fraction of image size\n",
        "\n",
        "    def augment_batch(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Apply random augmentations to a batch of images.\n",
        "        \"\"\"\n",
        "        X_aug = np.empty_like(X)\n",
        "        batch_size, C, H, W = X.shape\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            img = X[i].transpose(1, 2, 0)  # (H, W, C) for easier manipulation\n",
        "\n",
        "            # Random horizontal flip\n",
        "            if self.horizontal_flip and np.random.rand() < 0.5:\n",
        "                img = np.fliplr(img)\n",
        "\n",
        "            # Random rotation\n",
        "            if self.rotation_range > 0:\n",
        "                angle = np.random.uniform(-self.rotation_range, self.rotation_range)\n",
        "                img = rotate(img, angle, reshape=False, mode=\"reflect\")\n",
        "\n",
        "            # Random shift (translation)\n",
        "            if self.shift_range > 0:\n",
        "                shift_h = int(np.random.uniform(-self.shift_range, self.shift_range) * H)\n",
        "                shift_w = int(np.random.uniform(-self.shift_range, self.shift_range) * W)\n",
        "\n",
        "                # Create empty canvas\n",
        "                shifted = np.zeros_like(img)\n",
        "                h_start = max(0, shift_h)\n",
        "                h_end = H + min(0, shift_h)\n",
        "                w_start = max(0, shift_w)\n",
        "                w_end = W + min(0, shift_w)\n",
        "\n",
        "                shifted[h_start:h_end, w_start:w_end] = img[\n",
        "                    max(0, -shift_h):H - max(0, shift_h),\n",
        "                    max(0, -shift_w):W - max(0, shift_w)\n",
        "                ]\n",
        "                img = shifted\n",
        "\n",
        "            # Store back\n",
        "            X_aug[i] = img.transpose(2, 0, 1)  # back to (C, H, W)\n",
        "\n",
        "        return X_aug\n"
      ],
      "metadata": {
        "id": "MFmqfxe7He97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“ Updating Training Loop with Augmentation\n",
        "\n",
        "We integrate augmentation in the train loop (only for training batches, not validation/test):"
      ],
      "metadata": {
        "id": "4SXTSt1YMCKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train, y_train, X_val, y_val,\n",
        "          epochs=5, batch_size=64, lr=0.01, augment=False):\n",
        "    \"\"\"\n",
        "    Simple training loop with optional data augmentation.\n",
        "    \"\"\"\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "    optimizer = SGD(model, lr=lr)\n",
        "    augmenter = DataAugmentation() if augment else None\n",
        "\n",
        "    num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss, epoch_acc = 0, 0\n",
        "\n",
        "        # Shuffle training data\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            batch_idx = indices[i*batch_size:(i+1)*batch_size]\n",
        "            X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
        "\n",
        "            # Apply augmentation if enabled\n",
        "            if augment:\n",
        "                X_batch = augmenter.augment_batch(X_batch)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model.forward(X_batch, training=True)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn.forward(logits, y_batch)\n",
        "\n",
        "            # Backward pass\n",
        "            grad_logits = loss_fn.backward()\n",
        "            model.backward(grad_logits)\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track batch accuracy\n",
        "            acc = accuracy(logits, y_batch)\n",
        "            epoch_loss += loss\n",
        "            epoch_acc += acc\n",
        "\n",
        "        # Average over batches\n",
        "        epoch_loss /= num_batches\n",
        "        epoch_acc /= num_batches\n",
        "\n",
        "        # Validation\n",
        "        val_logits = model.forward(X_val, training=False)\n",
        "        val_loss = loss_fn.forward(val_logits, y_val)\n",
        "        val_acc = accuracy(val_logits, y_val)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "3hcJyyEnL-3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Example Usage with Augmentation"
      ],
      "metadata": {
        "id": "2FNOEsjxMIx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10\n",
        "X_train, y_train, X_test, y_test = load_cifar10()\n",
        "\n",
        "# Create validation split\n",
        "X_val, y_val = X_train[:500], y_train[:500]\n",
        "X_train, y_train = X_train[500:2500], y_train[500:2500]  # use only 2000 samples for speed\n",
        "\n",
        "print(\"Train set:\", X_train.shape, y_train.shape)\n",
        "print(\"Val set:\", X_val.shape, y_val.shape)\n",
        "\n",
        "# Create model\n",
        "model = MiniVGG(num_classes=10)\n",
        "\n",
        "# Train (with augmentation enabled)\n",
        "train(model,\n",
        "      X_train, y_train,\n",
        "      X_val, y_val,\n",
        "      epochs=3, batch_size=32, lr=0.01,\n",
        "      augment=True)\n",
        "\n",
        "# Quick test evaluation on 200 test images\n",
        "loss_fn = CrossEntropyLoss()\n",
        "logits = model.forward(X_test[:200], training=False)\n",
        "test_loss = loss_fn.forward(logits, y_test[:200])\n",
        "test_acc = accuracy(logits, y_test[:200])\n",
        "\n",
        "print(f\"Subset Test Loss: {test_loss:.4f}, Subset Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "Kn3UJlVoPUHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes\n",
        "\n",
        "    Flip: makes network invariant to left-right orientation.\n",
        "\n",
        "    Rotation: helps recognize rotated objects.\n",
        "\n",
        "    Shift: teaches robustness to translation.\n",
        "\n",
        "    Only applied during training; validation/test sets are left untouched."
      ],
      "metadata": {
        "id": "_OXGRFkbMqR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âš ï¸ Training on full CIFAR-10 (50,000 images) with NumPy CNN will be very slow.<br>\n",
        "ðŸ‘‰ For testing, use smaller subsets first (X_train[:2000], etc.), then scale up."
      ],
      "metadata": {
        "id": "isMZ_tykMxt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s add a visualization helper so you can see how your CIFAR-10 images look before and after augmentation."
      ],
      "metadata": {
        "id": "sesU2COqM8qC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“ Visualization Function"
      ],
      "metadata": {
        "id": "XcekGX_oNAea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def show_augmentation(X_batch, augmenter, n=5):\n",
        "    \"\"\"\n",
        "    Visualize original vs augmented images side by side.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X_batch : np.ndarray\n",
        "        A batch of images (N, C, H, W)\n",
        "    augmenter : DataAugmentation\n",
        "        Augmentation object\n",
        "    n : int\n",
        "        Number of samples to display\n",
        "    \"\"\"\n",
        "    # Pick first n images\n",
        "    X_orig = X_batch[:n]\n",
        "    X_aug = augmenter.augment_batch(X_orig.copy())\n",
        "\n",
        "    plt.figure(figsize=(2*n, 4))\n",
        "\n",
        "    for i in range(n):\n",
        "        # Original\n",
        "        plt.subplot(2, n, i+1)\n",
        "        img = X_orig[i].transpose(1, 2, 0)  # (H,W,C)\n",
        "        plt.imshow(np.clip(img, 0, 1))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"Original\")\n",
        "\n",
        "        # Augmented\n",
        "        plt.subplot(2, n, n+i+1)\n",
        "        img_aug = X_aug[i].transpose(1, 2, 0)\n",
        "        plt.imshow(np.clip(img_aug, 0, 1))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"Augmented\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ncwDUhp1Mtr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Example Usage"
      ],
      "metadata": {
        "id": "8h2BRZGwNJkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a small batch of CIFAR-10\n",
        "X_train, y_train, X_test, y_test = load_cifar10()\n",
        "augmenter = DataAugmentation(horizontal_flip=True, rotation_range=20, shift_range=0.2)\n",
        "\n",
        "# Show first 5 images before/after augmentation\n",
        "show_augmentation(X_train[:5], augmenter, n=5)"
      ],
      "metadata": {
        "id": "FepEfAIuNKFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate Scheduling\n",
        "ðŸ‘‰ Learning rate scheduling means changing the learning rate during training to improve convergence.\n",
        "\n",
        "Typical policies:\n",
        "\n",
        "    Step decay: reduce lr every few epochs (e.g., lr *= 0.1 every 10 epochs).\n",
        "\n",
        "    Exponential decay: lr = lr * exp(-decay * epoch).\n",
        "\n",
        "    Plateau decay: reduce lr when validation accuracy stops improving."
      ],
      "metadata": {
        "id": "AJYqcdNIRwtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code: Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "YwWgpeiHSLMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train, y_train, X_val, y_val,\n",
        "          epochs=5, batch_size=64, lr=0.01, augment=False,\n",
        "          scheduler=None):\n",
        "    \"\"\"\n",
        "    Training loop with optional augmentation and LR scheduler.\n",
        "    \"\"\"\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "    optimizer = SGD(model, lr=lr)\n",
        "    augmenter = DataAugmentation() if augment else None\n",
        "\n",
        "    num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss, epoch_acc = 0, 0\n",
        "\n",
        "        # Shuffle training data\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            batch_idx = indices[i*batch_size:(i+1)*batch_size]\n",
        "            X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
        "\n",
        "            if augment:\n",
        "                X_batch = augmenter.augment_batch(X_batch)\n",
        "\n",
        "            # Forward\n",
        "            logits = model.forward(X_batch, training=True)\n",
        "            loss = loss_fn.forward(logits, y_batch)\n",
        "\n",
        "            # Backward\n",
        "            grad_logits = loss_fn.backward()\n",
        "            model.backward(grad_logits)\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            acc = accuracy(logits, y_batch)\n",
        "            epoch_loss += loss\n",
        "            epoch_acc += acc\n",
        "\n",
        "        # Average over batches\n",
        "        epoch_loss /= num_batches\n",
        "        epoch_acc /= num_batches\n",
        "\n",
        "        # Validation\n",
        "        val_logits = model.forward(X_val, training=False)\n",
        "        val_loss = loss_fn.forward(val_logits, y_val)\n",
        "        val_acc = accuracy(val_logits, y_val)\n",
        "\n",
        "        # Apply LR scheduling\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "nkJ4Ox2UNMlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”§ Update Training Loop"
      ],
      "metadata": {
        "id": "h5X_k5fLSQfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train, y_train, X_val, y_val,\n",
        "          epochs=5, batch_size=64, lr=0.01, augment=False,\n",
        "          scheduler=None):\n",
        "    \"\"\"\n",
        "    Training loop with optional augmentation and LR scheduler.\n",
        "    \"\"\"\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "    optimizer = SGD(model, lr=lr)\n",
        "    augmenter = DataAugmentation() if augment else None\n",
        "\n",
        "    num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss, epoch_acc = 0, 0\n",
        "\n",
        "        # Shuffle training data\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            batch_idx = indices[i*batch_size:(i+1)*batch_size]\n",
        "            X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
        "\n",
        "            if augment:\n",
        "                X_batch = augmenter.augment_batch(X_batch)\n",
        "\n",
        "            # Forward\n",
        "            logits = model.forward(X_batch, training=True)\n",
        "            loss = loss_fn.forward(logits, y_batch)\n",
        "\n",
        "            # Backward\n",
        "            grad_logits = loss_fn.backward()\n",
        "            model.backward(grad_logits)\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            acc = accuracy(logits, y_batch)\n",
        "            epoch_loss += loss\n",
        "            epoch_acc += acc\n",
        "\n",
        "        # Average over batches\n",
        "        epoch_loss /= num_batches\n",
        "        epoch_acc /= num_batches\n",
        "\n",
        "        # Validation\n",
        "        val_logits = model.forward(X_val, training=False)\n",
        "        val_loss = loss_fn.forward(val_logits, y_val)\n",
        "        val_acc = accuracy(val_logits, y_val)\n",
        "\n",
        "        # Apply LR scheduling\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "r0Gx9UFXSRAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Example Usage"
      ],
      "metadata": {
        "id": "q1h_9k0uSXaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on a small subset with LR scheduling\n",
        "model = MiniVGG(num_classes=10)\n",
        "scheduler = LRScheduler(optimizer=SGD(model, lr=0.01), step_size=2, gamma=0.5)\n",
        "\n",
        "train(model,\n",
        "      X_train[:2000], y_train[:2000],\n",
        "      X_val[:500], y_val[:500],\n",
        "      epochs=6, batch_size=64, lr=0.01,\n",
        "      augment=True,\n",
        "      scheduler=scheduler)\n"
      ],
      "metadata": {
        "id": "XOD06PwYSX_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“ Confusion Matrix + Per-Class Accuracy"
      ],
      "metadata": {
        "id": "Xnm5sPIkSpCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def confusion_matrix(preds: np.ndarray, labels: np.ndarray, num_classes=10):\n",
        "    \"\"\"\n",
        "    Compute confusion matrix.\n",
        "\n",
        "    preds: model predictions (N,) or logits (N, num_classes)\n",
        "    labels: true labels (N,)\n",
        "    \"\"\"\n",
        "    if preds.ndim > 1:  # if logits, take argmax\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    for t, p in zip(labels, preds):\n",
        "        cm[t, p] += 1\n",
        "    return cm\n",
        "\n",
        "def per_class_accuracy(cm: np.ndarray):\n",
        "    \"\"\"\n",
        "    Compute per-class accuracy from confusion matrix.\n",
        "    \"\"\"\n",
        "    accs = cm.diagonal() / cm.sum(axis=1, where=(cm.sum(axis=1)!=0))\n",
        "    return accs\n",
        "\n",
        "def plot_confusion_matrix(cm: np.ndarray, class_names=None, title=\"Confusion Matrix\"):\n",
        "    \"\"\"\n",
        "    Display confusion matrix using heatmap.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "m6EOnRDhSnNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Example Usage After Training"
      ],
      "metadata": {
        "id": "M20kBZp3Su_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume model is trained already\n",
        "\n",
        "# Forward pass on test set (smaller subset for speed)\n",
        "logits = model.forward(X_test[:1000], training=False)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(logits, y_test[:1000], num_classes=10)\n",
        "\n",
        "# Per-class accuracy\n",
        "accs = per_class_accuracy(cm)\n",
        "for i, acc in enumerate(accs):\n",
        "    print(f\"Class {i}: {acc:.2f}\")\n",
        "\n",
        "# Plot matrix\n",
        "plot_confusion_matrix(cm, class_names=[str(i) for i in range(10)])\n"
      ],
      "metadata": {
        "id": "SNp4h4B4St56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes\n",
        "\n",
        "    Confusion matrix â†’ shows how many times each class was predicted correctly (diagonal) vs. misclassified (off-diagonal).\n",
        "\n",
        "    Per-class accuracy â†’ fraction of correct predictions for each class.\n",
        "\n",
        "    Plotting â†’ heatmap visualization makes it easy to spot which classes the network struggles with."
      ],
      "metadata": {
        "id": "gSbEM-sTS26A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Feature Visualization."
      ],
      "metadata": {
        "id": "T8MwNeURTA0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now letâ€™s move to README Part 4: Feature Visualization.\n",
        "\n",
        "The README requires two things:\n",
        "\n",
        "    Filter Visualization â†’ show the learned filters of the first Conv layer.\n",
        "\n",
        "    Feature Map Visualization â†’ show activations (feature maps) inside the network for a sample image."
      ],
      "metadata": {
        "id": "g51K7NdfTFHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“ Filter Visualization"
      ],
      "metadata": {
        "id": "iat0kIGTTL55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_filters(conv_layer, save_path=\"filters.png\"):\n",
        "    \"\"\"\n",
        "    Visualize learned filters of the first Conv2D layer.\n",
        "\n",
        "    conv_layer: Conv2D object\n",
        "    \"\"\"\n",
        "    W = conv_layer.params[\"W\"]  # shape (out_channels, in_channels, kh, kw)\n",
        "    num_filters = W.shape[0]\n",
        "    num_channels = W.shape[1]\n",
        "\n",
        "    # Normalize filters to 0-1 for display\n",
        "    W_min, W_max = W.min(), W.max()\n",
        "    W = (W - W_min) / (W_max - W_min + 1e-8)\n",
        "\n",
        "    # Plot each filter\n",
        "    cols = 8\n",
        "    rows = int(np.ceil(num_filters / cols))\n",
        "    plt.figure(figsize=(cols, rows))\n",
        "\n",
        "    for i in range(num_filters):\n",
        "        f = W[i]\n",
        "        if num_channels == 3:  # RGB filters\n",
        "            f_img = np.transpose(f, (1,2,0))\n",
        "        else:  # grayscale\n",
        "            f_img = f[0]\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(f_img, cmap=\"viridis\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.suptitle(\"Learned Filters\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "g_CJ3jcxS2fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“ Feature Map Visualization"
      ],
      "metadata": {
        "id": "5qUUC9MkTPcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_feature_maps(model, X_sample, layer_indices, save_path=\"feature_maps.png\"):\n",
        "    \"\"\"\n",
        "    Visualize feature maps at specified layers.\n",
        "\n",
        "    model: LeNet5 or MiniVGG instance\n",
        "    X_sample: single image (C, H, W)\n",
        "    layer_indices: list of indices of layers to visualize\n",
        "    \"\"\"\n",
        "    x = X_sample[np.newaxis, ...]  # add batch dim\n",
        "    activations = []\n",
        "\n",
        "    # Forward pass while storing intermediate outputs\n",
        "    for idx, layer in enumerate(model.layers):\n",
        "        x = layer.forward(x, training=False)\n",
        "        if idx in layer_indices:\n",
        "            activations.append((idx, x.copy()))\n",
        "\n",
        "    # Plot\n",
        "    for idx, act in activations:\n",
        "        num_maps = act.shape[1]\n",
        "        cols = 8\n",
        "        rows = int(np.ceil(num_maps / cols))\n",
        "        plt.figure(figsize=(cols, rows))\n",
        "        for i in range(num_maps):\n",
        "            plt.subplot(rows, cols, i+1)\n",
        "            plt.imshow(act[0, i], cmap=\"gray\")\n",
        "            plt.axis(\"off\")\n",
        "        plt.suptitle(f\"Feature Maps at Layer {idx}\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"feature_maps_layer{idx}.png\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "KIZCh1KOSaJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Example Usage"
      ],
      "metadata": {
        "id": "-kgkzML_TUjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After training your model\n",
        "# Show filters of first Conv layer\n",
        "visualize_filters(model.layers[0])\n",
        "\n",
        "# Pick one test image\n",
        "X_sample = X_test[0]\n",
        "\n",
        "# Show feature maps at some Conv layers\n",
        "visualize_feature_maps(model, X_sample, layer_indices=[0, 3, 7])\n"
      ],
      "metadata": {
        "id": "AdyCXQ5iTWi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes**\n",
        "\n",
        "    Filters (weights of conv kernels) in early layers often look like edge detectors or color blobs.\n",
        "\n",
        "    Feature maps show what each channel is â€œlooking forâ€ in the image (edges, textures, shapes).\n",
        "\n",
        "    As you go deeper â†’ features become more abstract (object parts, high-level patterns)."
      ],
      "metadata": {
        "id": "-Dfj200YTaYB"
      }
    }
  ]
}